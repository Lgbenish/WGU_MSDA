---
output:
  html_document: default
  pdf_document: default
---
---
title: "D213 Task 1"
author: "Lucas Benish"
date: '2023-06-30'
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

## Part 1: Research Question

### A. Describe the purpose of this data analysis by doing the following

#### 1. Summarize one research question that is relevant to a real-world organizational situation captured in the selected data set and that you will answer using time series modeling techniques.

One research question that I will seek to answer within this course is
the following: utilizing the given 2-years of revenue data, can we split
the data into training and testing sets and accurately predict revenue?

#### 2. Define the objectives or goals of the data analysis. Ensure that your objectives or goals are reasonable within the scope of the scenario and is represented in the available data.

The overarching goal of this analysis will include building a predictive
time series model that will allow us to forecast revenue of the
hospital.

## Part 2: Method Justification

### B. Summarize the assumptions of a time series model including stationarity and autocorrelated data.

Assumptions of a time series model include, but are not limited to, the
following:\
\* Consecutive observations within the data set are evenly spaced
(DataCamp, Time Series Analysis in R).\
\* The time series applies a discrete time observation index (or
approximates a discrete time observation index).\
\* The time series data is stationary.\
+ Stationarity is defined as time series observations having a constant
mean, variance, and covariance (DataCamp).\
\* Residuals of the time series data are not aurocorrelated.\
+ Autocorrelation represents the correlation that data points within the
time series have to a past value of themselves. The difference in time
between the current and past value is known as the "lag" between the
values.

## Part 3: Data Preparation

### C. Summarize the data cleaning process by doing the following

#### 1. Provide a line graph visualizing the realization of the time series

Prior to creating a visualization of the data, the data must first be
imported after the R Studio environment is setup. The following code
blocks setup my environment and import the data set. After this, the
line graph of the data set will be visualized.

##### setting up environment with needed libraries

```{r}
library(readr)
library(naniar)
library(visdat)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(tseries)
library(forecast)
library(astsa)
```

##### import data set

```{r}
medical_tseries <-read_csv("C:/Users/lgben/OneDrive/Desktop/MSDA/D213 - Advanced Data Analysis/Task 1/medical_time_series .csv") 
medical_tseries_copy <- medical_tseries
```

##### visualizing the data

```{r}
ggplot(medical_tseries_copy, aes(x=Day, y=Revenue)) + geom_line() + geom_smooth(method = lm)
```

The above is a graphical representation of the time series prior to any
cleaning/modification of the data set. Ggplot was utilized for
visualization, as the data set is not yet a time series. For this
reason, ts.plot() was not yet utilized.

#### 2. Describe the time step formatting of the realization, including any gaps in measurement and length of the sequence.

##### checking/cleaning data set

```{r}
summary(medical_tseries)
sum(is.null(medical_tseries[,1]))
sum(is.null(medical_tseries[,2]))
sum(duplicated(medical_tseries[1,]))
sum(duplicated(medical_tseries))
```

The output from the above lines of code show us that the data set begins
on "day" 1 and ends on "day" 731. These days are not going to be
modified into a specific "date" format for this analysis, as I am unsure
when specific dates these are referencing. The call of sum(is.null())
shows us that there are no NULL values within the data set. The next two
sum() calls show us that none of the days are duplicated within the data
set, nor are any of the day-revenue combinations duplicated within the
data set.

##### converting into timeseries

```{r}
is.ts(medical_tseries)  #false
medical_tseries <- as.ts(medical_tseries)
is.ts(medical_tseries)  #true
medical_tseries_rev <- as.ts(medical_tseries_copy$Revenue)
ts.plot(medical_tseries_rev, xlab = "Time in Days", ylab = "Revenue (in $Millions)", main = "Hospital Revenue Per Day")
start(medical_tseries)
end(medical_tseries)
frequency(medical_tseries)
#(Matteson, n.d.)
```

The above lines of code are utilized to convert my data frame into a
time series. It can be seen that the initially imported data frame is
not a time series. However, utilizing as.ts() coerces the data frame
into a time series. Following this, a vector is created to contain
solely the revenue values from the time series, but this is pulled from
the initial copy that was created after importing the data frame.

Another plot is then created, this time utilizing ts.plot() as the data
frame has been converted. After this, further verification on the
frequency of the data is performed utilizing start(), end(), and
frequency() (Matteson, n.d.). It is seen that the time series begins at
"day" 1, ends at "day" 731, and has a step of 1 day between
observations.

#### 3. Evaluate the stationarity of the time series.

##### evaluating stationarity

```{r}
kpss.test(medical_tseries_rev, null="Trend")  #output is 0.01, reject null
diffed_med_ts_rev <- diff(medical_tseries_rev)
kpss.test(diffed_med_ts_rev, null="Trend")  #output is 0.1, fail to reject null
#(Statology, 2022)
```

A KPSS test, or Kwiatkowski-PhillipsSchmidt-Shin test, can be utilized
to determine the stationarity of a time series. The null hypothesis is
that a trend is stationary, while the alternative hypothesis is that the
trend is not stationary (Statology, 2022). When the p-value of the test
is less than a specified significance level, the null hypothesis is
rejected.

With the initial KPSS test on the univariate time series (revenue), the
p-value is less than 0.05, meaning that the null hypothesis is rejected.
This means that the time series does not have a stationary trend. The
medical_tseries_rev was then called with the diff() function to
difference the time series. Differencing the time series, just once in
this instance, was enough to coerce stationarity as the null hypothesis
of the KPSS test was not rejected on the 2nd performance.

#### 4. Explain the steps used to prepare the data for analysis, including the training and test set split.

The steps used to prepare the data for analysis can predominantly be
seen within C1 to C3. C1 entailed establishing the R Studio environment,
importing the data set, exploring the data set visually to become
acquainted with the data. C2 entailed quantifying null and duplicated
values, as well as formatting the time series. C3 determined whether the
time series was stationary, and after determining that it was not was
coerced into a stationary time series.

##### splitting into train/test

```{r}
train_diff_med_ts_rev <- head(diffed_med_ts_rev, round(length(medical_tseries_rev)*0.8)) 
#training will be first portion of observations, so we can forecast
#split will be 80:20, hence looking for rounded 80% mark of rows
split_rowNBR <- length(diffed_med_ts_rev) - length(train_diff_med_ts_rev)  
test_diff_med_ts_rev <- tail(diffed_med_ts_rev, split_rowNBR)
#(Elleh, 2022)
```

The above code was adapted once again from Dr. Elleh's video, "D213 T1 R
Demo," and was utilized to split the differenced time series into
training and test time series. This was performed with the first 80% of
the time series, based on days, being included within the testing data
set. This will allow me to create a model for forecasting the latter 20%
of the time series, and allow for comparison against the actual, or
test, values.

#### 5. Provide a copy of the cleaned dataset.

##### writing train/test sets to folder

```{r}
write.csv(diffed_med_ts_rev, "C:/Users/lgben/OneDrive/Desktop/MSDA/D213 - Advanced Data Analysis/Task 1/diffed_med_ts_rev.csv")
write.csv(train_diff_med_ts_rev, "C:/Users/lgben/OneDrive/Desktop/MSDA/D213 - Advanced Data Analysis/Task 1/train_diff_med_ts_rev.csv")
write.csv(test_diff_med_ts_rev, "C:/Users/lgben/OneDrive/Desktop/MSDA/D213 - Advanced Data Analysis/Task 1/test_diff_med_ts_rev.csv")
```

The above lines of code will write the newly created training and test
time series, as well as the original time series, to my folder for
submission with the task.

## Part 4: Model Identification and Analysis

### D. Analyze the time series dataset by doing the following:

#### 1. Report the annotated findings with visualizations of your data analysis, including the following elements:

##### The presence or lack of a seasonal component

##### seasonality checked utilizing training revenue from original dataframe

```{r}
med_ts_weekly <- ts(medical_tseries_copy[, 2], frequency=731/7)
fit_weekly <- tbats(med_ts_weekly)
med_ts_monthly <- ts(medical_tseries_copy[, 2], frequency = 731/30)
fit_monthly <- tbats(med_ts_monthly)
seasonal_weekly <- !is.null(fit_weekly$seasonal)
print(seasonal_weekly)
#true denotes seasonality
seasonal_monthly <- !is.null(fit_monthly$seasonal)
print(seasonal_monthly)
#false denotes no seasonality
#(Hyndman, 2013)
```

The above portion of code demonstrates that there is a weekly (731/7)
seasonality, but no monthly (731/30 [approximate number of days in a month])
seasonality, within the original data set. This portion of code was
adapted from a response from Dr. R. Hyndman on StackExchange when reviewing how to assess for seasonality
in R (2013). This seasonality will also be demonstrated visually as well within the
decomposition portion.

For comparison, the below segment of code is adapted from Dr. Elleh's
video, "D213 T1 R Demo," wherein he creates a new time series vector,
based on the original data set, using only the training values without
being differenced. The frequency is set to 30 due to each step being 1
"day" and approximately 30 days being noted within a month. It would
appear that there is likely seasonality, although it is difficult to
determine within this plot. This will be revisited within the
decomposition portion of D1.

```{r}
train_med_ts <- ts(medical_tseries_copy[1:585, 2])
test_med_ts <- ts(medical_tseries_copy[586:731, 2])
train_medical_monthly_rev <- ts(medical_tseries_copy[1:585, 2], frequency = 30)
plot(train_medical_monthly_rev)
#(Elleh, 2022)
```

##### Trends

It was discovered during EDA (step C1) that a positive trend was noted within the
data set. This was noted within the visualization of the initial data frame. This trend however
was not noted following differencing of observations. The differencing step was performed
above in section C3 during the performance of the KPSS test. The
visualization will be provided below for reiteration that no trend now
exists.

```{r}
ggplot(medical_tseries_copy, aes(x=Day, y=Revenue)) + geom_line() + geom_smooth(method = lm)
ts.plot(diffed_med_ts_rev, xlab = "Time in Days", ylab = "Differenced Revenue (in $Millions)", main = "Differenced Hospital Revenue Per Day")
ts.plot(train_diff_med_ts_rev, xlab = "Time in Days", ylab = "Differenced Revenue (in $Millions)", main = "Differenced Hospital Revenue Per Day")
```

##### Autocorrelation functions

```{r}
acf(train_diff_med_ts_rev)
Pacf(train_diff_med_ts_rev)
acf2(train_diff_med_ts_rev)
#(Elleh, 2022)
```

Once again, the above code is adapted from Dr. Elleh's "D213 T1 R Demo" video. The data frames and time series have been renamed to fit my own personal naming conventions.

From the performance of the autocorrelation functions and partial
autocorrelation functions, the following can be seen. The ACF appears to
cut off at lag-2, while the PACF appears to cut off near lag-1, but continues
to have values of significance sporadically. These significant values
can be seen at lag-3, lag-6, and lag-18. These values can be confirmed
with the acf2() function. Per TowardsDataScience (2020), this may
warrant the use of an MA(2), or moving average, model for forecasting due to the PACF
"gradually decreasing" and the ACF cutting off at 2.

##### Spectral density

```{r}
spectrum(train_medical_monthly_rev)
```

The above is a visualization of the spectral density of
train_medical_monthly_rev. It is shown here that there is not a cyclical
nature to the data.

##### The decomposed time series

```{r}
med_tseries_comp <- decompose(train_medical_monthly_rev)
plot(med_tseries_comp)
```

Decomposing the time series here allows us to once again visualize what
we have seen in the above segments. Plotting the decomposition will
allow visualization of trends, seasonality, and the randomness/residuals. This
specific decomposition was performed on the monthly, training revenue
values prior to differencing. This is in line with performance by Dr.
Elleh in "D213 T1 R Demo," where the decomposition is performed prior to
differencing the observations.

##### Confirmation of the lack of trends in the residuals of the decomposed series

As will be confirmed from the plot below, the residuals from the
decomposition do not have a trend to them.

```{r}
plot(med_tseries_comp$random, xlab = "Month", ylab = "", main = "Residuals")
```

#### 2. Identify an autoregressive integrated moving average (ARIMA) model that takes into account the observed trend and seasonality of the time series data.

As stated in D1 - "autocorrelation" above, a model of MA(2)) is likely
an appropriate model for prediction. This is due to an ACF that cuts at
lag-2 and a PACF that gradually decreases, as shown by the sporadic
significant values at lag-3, lag-6, and lag-18.

##### begin model fitting

```{r}
set.seed(42)
arima(train_med_ts, order = c(0, 1, 2))
  #0 for AR
  #1 modifications needed for seasonality due to using a pre-differenced training set
  #2 used for MA(2) from above
med_ts_fit <- arima(train_med_ts, order = c(0, 1, 2))

auto.arima(train_med_ts)
#for comparison
#ends up utilizing same p, d, q
```

### 3. Perform a forecast using the derived ARIMA model

##### forecast

```{r}
med_ts_forecast <- forecast(med_ts_fit, h=146)
#146 is number of days remaining in test set to be predicted
plot(med_ts_forecast, xlab = "Time in Days", ylab = "Revenue (in $Millions)", main = "Hospital Revenue Per Day")
```

The forecast here is performed using the values that were determined
from the ACF and PACF, as well as those that were confirmed with the
auto_arima() function. For my forecast, a moving average was utilized
with 1 differencing required on the data set.

### 4. Provide the output and calculations of the analysis you performed

```{r}
summary(med_ts_fit)
med_pred_rev <- as.vector(med_ts_forecast$mean)
plot(med_ts_forecast)
lines(586:731, test_med_ts, col='red')
lines(586:731, med_pred_rev, col = 'green')
```

The above code demonstrates the summary of the ARIMA model fit on my training
time series. It also displays a graph with the predicted values of the
final 20% of the initial data set, shown in green. The actual values for
the final 20% of the data set that was previously set aside as the test
group are shown in red.

```{r}
#Ljung-box test
Box.test(med_ts_forecast$residuals)

#preparing for RMSE calculation
test_med_ts_vector <- as.vector(test_med_ts)
rmse_df <- data.frame(col1 = med_pred_rev, col2 = test_med_ts_vector)
rmse_df$Pred <- rmse_df$col1
rmse_df$Actual <- rmse_df$col2
rmse <- sqrt(mean((rmse_df$Pred - rmse_df$Actual)^2))
print(rmse)
```

Furthermore, the p-value of the Ljung-box test is provided. The null hypothesis of this test is that the residuals of a time series model are independently distributed (Statology, 2020). When the p-value is greater than the designated level of significance, the null hypothesis fails to be rejected. In this case, the p-value is \> 0.88, meaning the null hypothesis is not rejected.

The RMSE, or root mean square error, was calculated to be 3.56. This is
a measure of how accurate the revenue predictions are relative to the
actual revenue, on average. In this instance, the predicted values are
incorrect by \$3.56M on average.

### 5. Provide the code used to support the implementation of the time series model

All relevant code is shown above.

## Part 5: Data Summary and Implications

### E. Summarize your findings and assumptions, including the following points:

#### 1. Discuss the results of your data analysis, including the following:

##### The selection of an ARIMA model

##### The prediction interval of the forecast

##### A justification of the forecast length

##### The model evaluation procedure and error metrics

As stated above in section D1, the selection of my ARIMA model parameters was done
based on the ACF and PACF from the differenced training time series.
Based on the research that I found (TowardsDataScience, 2020), when
there is a gradually decreasing PACF and an ACF that cuts off at lag(p),
that time series would be best modeled utilizing an MA(p), or moving
average model of lag(p).

The prediction interval was determined based on the training and testing
data split. The training data was the first 80% of the overall
data set. This was done without randomization/shuffling to ensure that
all the data that was utilized for building the model was sequential.
The final 20% of the original data set then became the testing data.
This testing data then dictated the forecast length. Because the data
that remained spanned 146 days, the model was forecasted 146 days to
allow for comparisons. Forecasting beyond the data that was currently
available within the testing data would not make sense, as the accuracy
of that prediction could not currently be judged.

The model was evaluated in two different ways. First, the Ljung-box test
was performed in step D4. This test is utilized to determine if the
residuals of the model are independent of one another. It was discussed
in D4, but the residuals are, in fact, independent. Following this, the
predicted revenue values were then compared against the actual revenue
values to see how well the model was able to forecast. Overall, the
model did not do a great job of forecasting revenue. The forecast did
not show any positive or negative trend. Furthermore, the RMSE was off
by approximately \$3.5 million on average.

#### 2. Provide an annotated visualization of the forecast of the final model compared to the test set

```{r}
plot(med_ts_forecast, xlab = "Days", ylab = "Revenue (in $Millions)", main = "Actual vs Predicted Hospital Revenue")
lines(586:731, test_med_ts, col='red')
lines(586:731, med_pred_rev, col = 'green')
legend(1, 35, legend = c("Training Revenue", "Test Revenue", "Predicted Revenue"), col=c("black", "red", "green"),lty=1, cex=0.8)
```

The above code outputs the visualization of the training revenue, test
(actual) revenue, and predicted revenue for the hospital.

#### 3. Recommend a course of action based on your results

Based on the results of this analysis, and model with poor predictive
capabilities, I believe that an appropriate next step may be one of the
following:\
1. Create a new model utilizing the same data, but with different
parameters or with a different train/test split.\
2. Shorten the length of data utilized to predict revenue. A more
accurate model may be noted if only data within a specific calendar or
fiscal year is utilized. This will allow the new model to make predictions based only on more recent data.

## Part 6: Reporting

### F. Create your report from part E using an industry-relevant interactive development environment (e.g. a Jupyter Notebook). Include a PDF or HTML document of your executed notebook presentation

The above report has been created utilizing R Markdown. Both a PDF and
markdown file will be provided with my submission.

### G. Cite the web sources you used to acquire third-party code to support the application.

1.	Elleh, F. (2022, September 18). D213 T1 R Demo [Online Video Lecture]. Western Governors University. https://westerngovernorsuniversity-my.sharepoint.com/personal/festus_elleh_wgu_edu/_layouts/15/stream.aspx?id=%2Fpersonal%2Ffestus%5Felleh%5Fwgu%5Fedu%2FDocuments%2FDesktop%2FMSDA%20Courses%2FD213%20Advanced%20Data%20Analytics%2FCohort%20and%20Recording%2FD213%20T1%20R%20Demo%2Emp4 
2.	Hyndman, R. (2013, April 13). Identify seasonality in time series data [duplicate]. StackExchange. Retrieved June 29, 2023, from https://stats.stackexchange.com/questions/57705/identify-seasonality-in-time-series-data 
3.	Matteson, D. S. (n.d.) Time Series Analysis in R [Online Video Course]. DataCamp. https://app.datacamp.com/learn/courses/time-series-analysis-in-r 
4.	Z. (2022, January 19). How to Perform a KPSS Test in R (Including Example). Retrieved June 29, 2023, from https://www.statology.org/kpss-test-in-r/ 
5.	Z. (2020, February 14). Ljung-Box Test: Definition + Example. Retrieved June 29, 2023, from https://www.statology.org/ljung-box-test/ 



### H. Acknowledge sources, using in-text citations and references, for content that is quoted, paraphrased, or summarized.

1.	M. (2020, August 12). Time Series Analysis: Identifying AR and MA using ACF and PACF Plots. Towards Data Science. Retrieved June 29, 2023, from https://towardsdatascience.com/identifying-ar-and-ma-terms-using-acf-and-pacf-plots-in-time-series-forecasting-ccb9fd073db8 
2.	R Studio (2014, October 30). R Markdown Reference Guide. Retrieved June 29, 2023, from https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf 


### I. Demonstrate professional communication in the content and presentation of your submission..
